{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--manualSeed'], dest='manualSeed', nargs=None, const=None, default=None, type=<type 'int'>, choices=None, help='manual seed', metavar=None)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', required=True, help='cifar10 | lsun | imagenet | folder | lfw | fake')\n",
    "parser.add_argument('--dataroot', required=True, help='path to dataset')\n",
    "parser.add_argument('--workers', type=int, help='number of data loading workers', default=2)\n",
    "parser.add_argument('--batchSize', type=int, default=64, help='input batch size')\n",
    "parser.add_argument('--imageSize', type=int, default=64, help='the height / width of the input image to network')\n",
    "parser.add_argument('--nz', type=int, default=100, help='size of the latent z vector')\n",
    "parser.add_argument('--ngf', type=int, default=64)\n",
    "parser.add_argument('--ndf', type=int, default=64)\n",
    "parser.add_argument('--niter', type=int, default=25, help='number of epochs to train for')\n",
    "parser.add_argument('--lr', type=float, default=0.0002, help='learning rate, default=0.0002')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
    "parser.add_argument('--ngpu', type=int, default=1, help='number of GPUs to use')\n",
    "parser.add_argument('--netG', default='', help=\"path to netG (to continue training)\")\n",
    "parser.add_argument('--netD', default='', help=\"path to netD (to continue training)\")\n",
    "parser.add_argument('--outf', default='.', help='folder to output images and model checkpoints')\n",
    "parser.add_argument('--manualSeed', type=int, help='manual seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['batch_size']=100\n",
    "args['test_batch_size'] =1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  5\n"
     ]
    }
   ],
   "source": [
    "args['manualSeed'] = 5\n",
    "print(\"Random Seed: \", args['manualSeed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f59e44fa6d0>"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(args['manualSeed'])\n",
    "torch.manual_seed(args['manualSeed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['test_batch_size'], shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_use = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=args['batch_size'], shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_fan_in_and_fan_out(tensor):\n",
    "    dimensions = tensor.ndimension()\n",
    "    if dimensions < 2:\n",
    "        raise ValueError(\"Fan in and fan out can not be computed for tensor with less than 2 dimensions\")\n",
    "\n",
    "    if dimensions == 2:  # Linear\n",
    "        fan_in = tensor.size(1)\n",
    "        fan_out = tensor.size(0)\n",
    "    else:\n",
    "        num_input_fmaps = tensor.size(1)\n",
    "        num_output_fmaps = tensor.size(0)\n",
    "        receptive_field_size = 1\n",
    "        if tensor.dim() > 2:\n",
    "            receptive_field_size = tensor[0][0].numel()\n",
    "        fan_in = num_input_fmaps * receptive_field_size\n",
    "        fan_out = num_output_fmaps * receptive_field_size\n",
    "\n",
    "    return fan_in, fan_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "       # self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "      #  x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_networks = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_networks = 10\n",
    "for i in range(n_networks):\n",
    "    neural_networks[i] = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_loaders = {}\n",
    "\n",
    "for i  in range(n_networks):\n",
    "\n",
    "    training_loaders[i] = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=args['batch_size'], shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m, xavier=True, std_given=10., random_seed=1):\n",
    "    classname = m.__class__.__name__\n",
    "    random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    print (classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "       # m.weight.data.normal_(0.0, 0.02)\n",
    "        \n",
    "        if xavier:\n",
    "            z = _calculate_fan_in_and_fan_out(m.weight.data)\n",
    "            std = math.sqrt(2.0 / (z[0] + z[1]))\n",
    "            m.weight.data.uniform_(-std, std)\n",
    "        else:\n",
    "            m.weight.data.uniform_(-std_given, std_given)\n",
    "    if classname.find('Linear') != -1:\n",
    "        if xavier:\n",
    "            z = _calculate_fan_in_and_fan_out(m.weight.data)\n",
    "            std = math.sqrt(2.0 / (z[0] + z[1]))\n",
    "            m.weight.data.uniform_(-std, std)\n",
    "            \n",
    "            m.bias.data.fill_(0.0)\n",
    "        else:\n",
    "            m.weight.data.uniform_(-std_given, std_given)\n",
    "            m.bias.data.uniform_(-std_given, std_given)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d\n",
      "Conv2d\n",
      "Linear\n",
      "Linear\n",
      "Net\n",
      "Conv2d\n",
      "Conv2d\n",
      "Linear\n",
      "Linear\n",
      "Net\n",
      "Conv2d\n",
      "Conv2d\n",
      "Linear\n",
      "Linear\n",
      "Net\n",
      "Conv2d\n",
      "Conv2d\n",
      "Linear\n",
      "Linear\n",
      "Net\n",
      "Conv2d\n",
      "Conv2d\n",
      "Linear\n",
      "Linear\n",
      "Net\n",
      "Conv2d\n",
      "Conv2d\n",
      "Linear\n",
      "Linear\n",
      "Net\n",
      "Conv2d\n",
      "Conv2d\n",
      "Linear\n",
      "Linear\n",
      "Net\n",
      "Conv2d\n",
      "Conv2d\n",
      "Linear\n",
      "Linear\n",
      "Net\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, n_networks - 1):\n",
    "    magnitudes = 10 ** (- i + 4)\n",
    "    g = lambda x: weights_init(x, xavier=False, std_given=magnitudes, random_seed=i)\n",
    "    neural_networks[i].apply(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = [0, 1, 2, 3, 4, 5, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "(0 ,0 ,.,.) = \n",
       "1.00000e-02 *\n",
       "   6.6050 -7.4778  8.1494  6.3985  8.4021\n",
       "  -7.6671 -6.7122  4.7584 -9.3347  9.8837\n",
       "   2.1286  1.2914 -8.5518  3.1868  4.3001\n",
       "   1.5866  9.6185  3.0032 -8.8673  8.4022\n",
       "   3.3953 -4.7705 -9.1857  5.7007  9.5032\n",
       "\n",
       "(1 ,0 ,.,.) = \n",
       "1.00000e-02 *\n",
       "  -8.1931  0.5465  3.5877 -4.7224 -2.1881\n",
       "  -6.6773 -4.7277 -9.1167 -0.2318  5.9293\n",
       "   4.8637  9.3941 -8.7825 -1.2304  9.7363\n",
       "   1.6375 -2.8200 -9.0061  4.6534  7.5917\n",
       "   8.0187  8.3716  1.9578  7.1274 -2.5171\n",
       "\n",
       "(2 ,0 ,.,.) = \n",
       "1.00000e-02 *\n",
       "   8.1212 -0.8556 -2.0622 -4.9709  5.3243\n",
       "   4.0461  6.3608 -6.3907 -5.3170  9.4632\n",
       "  -5.5504 -5.7032 -2.6756 -3.2321 -6.8007\n",
       "   8.0813  1.1147  4.5591  7.4174 -6.4800\n",
       "   7.6339 -5.0095 -1.5921  7.5677  9.2197\n",
       "\n",
       "(3 ,0 ,.,.) = \n",
       "1.00000e-02 *\n",
       "   8.7785  5.7513  9.2947 -3.6031 -0.6365\n",
       "  -3.4203 -0.7350 -1.2159  5.3428  6.8734\n",
       "  -7.2011 -5.5220 -3.0755  1.3368 -3.8818\n",
       "  -6.2195 -1.8264 -4.8801  0.2753 -7.4026\n",
       "  -2.4998 -3.6897 -1.3813  7.8573  6.5572\n",
       "\n",
       "(4 ,0 ,.,.) = \n",
       "1.00000e-02 *\n",
       "  -3.2271 -9.1682 -7.1529 -7.6718 -0.9488\n",
       "  -4.4409 -6.9885  2.2172  0.6435 -1.4992\n",
       "  -3.6250  8.5232 -9.6337 -0.2382  4.6422\n",
       "   7.0605 -8.6998 -1.5659  8.3398  1.6461\n",
       "   3.0238 -4.4186  6.9403 -3.7499 -5.3850\n",
       "\n",
       "(5 ,0 ,.,.) = \n",
       "1.00000e-02 *\n",
       "   9.0706  2.6490 -0.0690 -6.9691 -2.2135\n",
       "  -7.6820 -6.7283 -1.4321  1.9332 -8.1937\n",
       "   9.7190  7.3548 -9.3064  6.2508 -6.0007\n",
       "  -8.1488  9.3685 -4.0212 -3.3172  1.2462\n",
       "   5.6522  0.7693 -2.6874  0.8479 -5.1811\n",
       "\n",
       "(6 ,0 ,.,.) = \n",
       "1.00000e-02 *\n",
       "  -7.2739  2.6038  1.0537  4.9689 -3.7149\n",
       "  -9.8839 -2.4813 -9.6761 -0.7873  4.8850\n",
       "   0.9252  5.7377  1.8652  4.2881  9.0014\n",
       "   1.4879  1.6641 -4.0575  6.2356  8.3887\n",
       "  -6.9456  9.7061  3.0165 -1.3956 -9.1522\n",
       "\n",
       "(7 ,0 ,.,.) = \n",
       "1.00000e-02 *\n",
       "  -9.9936 -7.8554 -8.3648 -6.6686 -2.9121\n",
       "  -8.3007 -8.3599 -1.1130 -8.4135 -0.9041\n",
       "   1.7036  1.8978  6.2756  5.4584 -5.6090\n",
       "  -3.3679  0.2290  8.4393  4.8532 -5.5961\n",
       "  -1.1733  1.8075  3.4731 -3.7159 -8.7756\n",
       "\n",
       "(8 ,0 ,.,.) = \n",
       "1.00000e-02 *\n",
       "  -6.0996  0.3438 -6.8242  2.7833  6.2859\n",
       "  -0.1092  5.2462  7.0050  6.3845 -9.5238\n",
       "   9.0634  2.6442 -9.9135  2.4884 -6.8860\n",
       "   9.2562  7.9293 -6.5958 -7.4118  0.7034\n",
       "  -2.6491  4.2818 -9.3157  7.4140  0.8967\n",
       "\n",
       "(9 ,0 ,.,.) = \n",
       "1.00000e-02 *\n",
       "   0.1964 -6.3786  0.6214  6.7939  9.7423\n",
       "  -6.4767 -4.1915  2.0796  5.6230 -8.3934\n",
       "  -3.7319 -7.9447  9.1891 -3.4125  6.0145\n",
       "   5.4511  0.9230  1.9505  6.5052 -1.2633\n",
       "   5.2628 -1.3307  0.1573  3.4183 -9.0222\n",
       "[torch.FloatTensor of size 10x1x5x5]"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=list(neural_networks[5].parameters())\n",
    "z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['lr'] = 0.01\n",
    "args['momentum'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['cuda'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {}\n",
    "\n",
    "for i in neural_networks:\n",
    "    optimizers[i] = optim.SGD(neural_networks[i].parameters(), lr=args['lr'], momentum=args['momentum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, train_loader):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args['cuda']:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if batch_idx % 10 == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "    model.eval()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in train_use:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        train_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "    print (train_loss, train_use.dataset)\n",
    "    train_loss /= len(train_use.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        train_loss, correct, len(train_loader.dataset),\n",
    "        100. * correct / len(train_loader.dataset)))\n",
    "    return 100. * correct / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for i in range(n_networks):\n",
    "    results[i] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16484.9489927 <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: 0.2747, Accuracy: 55161/60000 (92%)\n",
      "\n",
      "nan <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: nan, Accuracy: 5923/60000 (10%)\n",
      "\n",
      "nan <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: nan, Accuracy: 5923/60000 (10%)\n",
      "\n",
      "358689.187286 <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: 5.9782, Accuracy: 5918/60000 (10%)\n",
      "\n",
      "139539.714401 <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: 2.3257, Accuracy: 5949/60000 (10%)\n",
      "\n",
      "18976.6626759 <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: 0.3163, Accuracy: 54452/60000 (91%)\n",
      "\n",
      "16496.0890474 <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: 0.2749, Accuracy: 55023/60000 (92%)\n",
      "\n",
      "9878.59872007 <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: 0.1646, Accuracy: 57048/60000 (95%)\n",
      "\n",
      "nan <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: nan, Accuracy: 5923/60000 (10%)\n",
      "\n",
      "nan <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: nan, Accuracy: 5923/60000 (10%)\n",
      "\n",
      "218100.717163 <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: 3.6350, Accuracy: 6131/60000 (10%)\n",
      "\n",
      "138343.008514 <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: 2.3057, Accuracy: 6742/60000 (11%)\n",
      "\n",
      "12117.7893705 <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: 0.2020, Accuracy: 56406/60000 (94%)\n",
      "\n",
      "9987.42248058 <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: 0.1665, Accuracy: 57012/60000 (95%)\n",
      "\n",
      "7650.19424605 <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: 0.1275, Accuracy: 57655/60000 (96%)\n",
      "\n",
      "nan <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: nan, Accuracy: 5923/60000 (10%)\n",
      "\n",
      "nan <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: nan, Accuracy: 5923/60000 (10%)\n",
      "\n",
      "162454.863846 <torchvision.datasets.mnist.MNIST object at 0x7f59b57e3c90>\n",
      "\n",
      "Test set: Average loss: 2.7076, Accuracy: 6742/60000 (11%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 20 + 1):\n",
    "    for i in keep:\n",
    "        res = train(epoch, neural_networks[i], optimizers[i], training_loaders[i])\n",
    "        results[i].append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
