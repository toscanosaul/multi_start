{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--manualSeed'], dest='manualSeed', nargs=None, const=None, default=None, type=<type 'int'>, choices=None, help='manual seed', metavar=None)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', required=True, help='cifar10 | lsun | imagenet | folder | lfw | fake')\n",
    "parser.add_argument('--dataroot', required=True, help='path to dataset')\n",
    "parser.add_argument('--workers', type=int, help='number of data loading workers', default=2)\n",
    "parser.add_argument('--batchSize', type=int, default=64, help='input batch size')\n",
    "parser.add_argument('--imageSize', type=int, default=64, help='the height / width of the input image to network')\n",
    "parser.add_argument('--nz', type=int, default=100, help='size of the latent z vector')\n",
    "parser.add_argument('--ngf', type=int, default=64)\n",
    "parser.add_argument('--ndf', type=int, default=64)\n",
    "parser.add_argument('--niter', type=int, default=25, help='number of epochs to train for')\n",
    "parser.add_argument('--lr', type=float, default=0.0002, help='learning rate, default=0.0002')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
    "parser.add_argument('--ngpu', type=int, default=1, help='number of GPUs to use')\n",
    "parser.add_argument('--netG', default='', help=\"path to netG (to continue training)\")\n",
    "parser.add_argument('--netD', default='', help=\"path to netD (to continue training)\")\n",
    "parser.add_argument('--outf', default='.', help='folder to output images and model checkpoints')\n",
    "parser.add_argument('--manualSeed', type=int, help='manual seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['batch_size']=100\n",
    "args['test_batch_size'] =1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  5\n"
     ]
    }
   ],
   "source": [
    "args['manualSeed'] = 5\n",
    "print(\"Random Seed: \", args['manualSeed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f59e44fa6d0>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(args['manualSeed'])\n",
    "torch.manual_seed(args['manualSeed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['batch_size'], shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['test_batch_size'], shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_fan_in_and_fan_out(tensor):\n",
    "    dimensions = tensor.ndimension()\n",
    "    if dimensions < 2:\n",
    "        raise ValueError(\"Fan in and fan out can not be computed for tensor with less than 2 dimensions\")\n",
    "\n",
    "    if dimensions == 2:  # Linear\n",
    "        fan_in = tensor.size(1)\n",
    "        fan_out = tensor.size(0)\n",
    "    else:\n",
    "        num_input_fmaps = tensor.size(1)\n",
    "        num_output_fmaps = tensor.size(0)\n",
    "        receptive_field_size = 1\n",
    "        if tensor.dim() > 2:\n",
    "            receptive_field_size = tensor[0][0].numel()\n",
    "        fan_in = num_input_fmaps * receptive_field_size\n",
    "        fan_out = num_output_fmaps * receptive_field_size\n",
    "\n",
    "    return fan_in, fan_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "       # self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "      #  x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_networks = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_networks = 10\n",
    "for i in range(n_networks):\n",
    "    neural_networks[i] = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m, xavier=True, std_given=10., random_seed=1):\n",
    "    classname = m.__class__.__name__\n",
    "    random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    print (classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "       # m.weight.data.normal_(0.0, 0.02)\n",
    "        \n",
    "        if xavier:\n",
    "            z = _calculate_fan_in_and_fan_out(m.weight.data)\n",
    "            std = math.sqrt(2.0 / (z[0] + z[1]))\n",
    "            m.weight.data.uniform_(-std, std)\n",
    "        else:\n",
    "            m.weight.data.uniform_(-std_given, std_given)\n",
    "    if classname.find('Linear') != -1:\n",
    "        if xavier:\n",
    "            z = _calculate_fan_in_and_fan_out(m.weight.data)\n",
    "            std = math.sqrt(2.0 / (z[0] + z[1]))\n",
    "            m.weight.data.uniform_(-std, std)\n",
    "            \n",
    "            m.bias.data.fill_(0.0)\n",
    "        else:\n",
    "            m.weight.data.uniform_(-std_given, std_given)\n",
    "            m.bias.data.uniform_(-std_given, std_given)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d\n",
      "Conv2d\n",
      "Linear\n",
      "Linear\n",
      "Net\n",
      "Conv2d\n",
      "Conv2d\n",
      "Linear\n",
      "Linear\n",
      "Net\n",
      "Conv2d\n",
      "Conv2d\n",
      "Linear\n",
      "Linear\n",
      "Net\n",
      "Conv2d\n",
      "Conv2d\n",
      "Linear\n",
      "Linear\n",
      "Net\n",
      "Conv2d\n",
      "Conv2d\n",
      "Linear\n",
      "Linear\n",
      "Net\n",
      "Conv2d\n",
      "Conv2d\n",
      "Linear\n",
      "Linear\n",
      "Net\n",
      "Conv2d\n",
      "Conv2d\n",
      "Linear\n",
      "Linear\n",
      "Net\n",
      "Conv2d\n",
      "Conv2d\n",
      "Linear\n",
      "Linear\n",
      "Net\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, n_networks - 1):\n",
    "    magnitudes = 10 ** (- i + 4)\n",
    "    g = lambda x: weights_init(x, xavier=False, std_given=magnitudes, random_seed=i)\n",
    "    neural_networks[i].apply(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "(0 ,0 ,.,.) = \n",
       "  0.0549  0.1943 -0.1287  0.0482 -0.1890\n",
       "  0.1021  0.1862 -0.1877 -0.1574 -0.1975\n",
       "  0.0497  0.0365  0.0583 -0.1731 -0.1708\n",
       "  0.1353  0.1250 -0.1063  0.1920  0.0898\n",
       "  0.0657 -0.1477  0.1153 -0.1384 -0.1394\n",
       "\n",
       "(1 ,0 ,.,.) = \n",
       "  0.0384  0.0115  0.1107 -0.1991 -0.0923\n",
       "  0.1488 -0.0196 -0.0450 -0.0378  0.1518\n",
       " -0.0167 -0.0258 -0.0344 -0.0179 -0.1215\n",
       "  0.1152 -0.1092  0.0906  0.1200 -0.1950\n",
       "  0.0801 -0.1447 -0.1155  0.1131  0.0719\n",
       "\n",
       "(2 ,0 ,.,.) = \n",
       " -0.1394  0.0344  0.1518  0.1342  0.0521\n",
       "  0.1644  0.1650  0.0347 -0.1053 -0.1411\n",
       " -0.0823  0.1888 -0.1808 -0.1411 -0.1516\n",
       " -0.1491 -0.1189  0.1800  0.0182  0.0174\n",
       "  0.1368 -0.0452 -0.0520 -0.1024  0.0933\n",
       "\n",
       "(3 ,0 ,.,.) = \n",
       "  0.1441  0.1597  0.0736 -0.1854  0.1572\n",
       "  0.0377 -0.0340 -0.0472 -0.0161  0.1869\n",
       " -0.0773 -0.0068 -0.0037  0.1552  0.0608\n",
       "  0.1361  0.0094  0.1046  0.0421  0.1084\n",
       " -0.0929 -0.0618 -0.0526 -0.0997  0.0586\n",
       "\n",
       "(4 ,0 ,.,.) = \n",
       " -0.0483  0.0806  0.0401  0.0348 -0.0240\n",
       "  0.0256  0.1308 -0.1005 -0.0335  0.0274\n",
       " -0.0739  0.0537  0.0400 -0.1219  0.1804\n",
       "  0.0036  0.1889  0.0174  0.0916 -0.0904\n",
       " -0.1424 -0.1459 -0.0369  0.1094 -0.0683\n",
       "\n",
       "(5 ,0 ,.,.) = \n",
       "  0.0638 -0.0837 -0.1216 -0.1999 -0.1119\n",
       " -0.1797  0.1972  0.0112 -0.0515 -0.0332\n",
       " -0.1756  0.0123  0.0976  0.0286 -0.0048\n",
       " -0.0800 -0.0780  0.1913  0.0525  0.0610\n",
       " -0.0854 -0.0133 -0.1026  0.0755 -0.0938\n",
       "\n",
       "(6 ,0 ,.,.) = \n",
       " -0.1149  0.1057  0.1666 -0.0072 -0.0582\n",
       "  0.0587 -0.1672  0.1287 -0.0860 -0.0033\n",
       "  0.1853 -0.0078 -0.1349  0.1918 -0.1719\n",
       "  0.0203  0.1169 -0.0057 -0.1131  0.0233\n",
       "  0.0702  0.0200  0.1271  0.0831  0.0617\n",
       "\n",
       "(7 ,0 ,.,.) = \n",
       "  0.0512 -0.0008  0.1324  0.1126 -0.0315\n",
       " -0.1750  0.1148 -0.0541 -0.1650  0.1906\n",
       "  0.1463  0.1250 -0.1519 -0.1430  0.0058\n",
       " -0.1966 -0.0275 -0.0092  0.0737  0.0547\n",
       "  0.1352  0.0478  0.0213 -0.0529  0.1213\n",
       "\n",
       "(8 ,0 ,.,.) = \n",
       " -0.0024  0.1675  0.0225  0.0500  0.1578\n",
       " -0.1458 -0.1836  0.0492  0.1840 -0.0459\n",
       "  0.1136 -0.1878 -0.0732 -0.0087  0.0577\n",
       " -0.0857 -0.0183  0.1418 -0.0747  0.0699\n",
       "  0.1103 -0.0144 -0.0283  0.0833  0.1509\n",
       "\n",
       "(9 ,0 ,.,.) = \n",
       "  0.1706 -0.0472  0.0840 -0.0409  0.0264\n",
       "  0.1106 -0.1660 -0.1986 -0.0631  0.0009\n",
       "  0.1499 -0.0118 -0.1030 -0.0821 -0.0030\n",
       " -0.0548  0.0303 -0.1149 -0.0734  0.1075\n",
       "  0.0775  0.0291 -0.1732 -0.1559  0.0805\n",
       "[torch.FloatTensor of size 10x1x5x5]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=list(neural_networks[9].parameters())\n",
    "z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['lr'] = 0.01\n",
    "args['momentum'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['cuda'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {}\n",
    "\n",
    "for i in neural_networks:\n",
    "    optimizers[i] = optim.SGD(neural_networks[i].parameters(), lr=args['lr'], momentum=args['momentum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args['cuda']:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if batch_idx % 10 == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "    model.eval()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in train_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        train_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        train_loss, correct, len(train_loader.dataset),\n",
    "        100. * correct / len(train_loader.dataset)))\n",
    "    return 100. * correct / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for i in range(n_networks):\n",
    "    results[i] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 50 + 1):\n",
    "    for i in range(n_networks):\n",
    "        res = train(epoch, neural_networks[i], optimizers[i])\n",
    "        results[i].append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
