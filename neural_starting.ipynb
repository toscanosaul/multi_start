{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--manualSeed'], dest='manualSeed', nargs=None, const=None, default=None, type=<type 'int'>, choices=None, help='manual seed', metavar=None)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', required=True, help='cifar10 | lsun | imagenet | folder | lfw | fake')\n",
    "parser.add_argument('--dataroot', required=True, help='path to dataset')\n",
    "parser.add_argument('--workers', type=int, help='number of data loading workers', default=2)\n",
    "parser.add_argument('--batchSize', type=int, default=64, help='input batch size')\n",
    "parser.add_argument('--imageSize', type=int, default=64, help='the height / width of the input image to network')\n",
    "parser.add_argument('--nz', type=int, default=100, help='size of the latent z vector')\n",
    "parser.add_argument('--ngf', type=int, default=64)\n",
    "parser.add_argument('--ndf', type=int, default=64)\n",
    "parser.add_argument('--niter', type=int, default=25, help='number of epochs to train for')\n",
    "parser.add_argument('--lr', type=float, default=0.0002, help='learning rate, default=0.0002')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
    "parser.add_argument('--ngpu', type=int, default=1, help='number of GPUs to use')\n",
    "parser.add_argument('--netG', default='', help=\"path to netG (to continue training)\")\n",
    "parser.add_argument('--netD', default='', help=\"path to netD (to continue training)\")\n",
    "parser.add_argument('--outf', default='.', help='folder to output images and model checkpoints')\n",
    "parser.add_argument('--manualSeed', type=int, help='manual seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['batch_size']=100\n",
    "args['test_batch_size'] =1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  5\n"
     ]
    }
   ],
   "source": [
    "args['manualSeed'] = 5\n",
    "print(\"Random Seed: \", args['manualSeed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f59e44fa6d0>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(args['manualSeed'])\n",
    "torch.manual_seed(args['manualSeed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['batch_size'], shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['test_batch_size'], shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_fan_in_and_fan_out(tensor):\n",
    "    dimensions = tensor.ndimension()\n",
    "    if dimensions < 2:\n",
    "        raise ValueError(\"Fan in and fan out can not be computed for tensor with less than 2 dimensions\")\n",
    "\n",
    "    if dimensions == 2:  # Linear\n",
    "        fan_in = tensor.size(1)\n",
    "        fan_out = tensor.size(0)\n",
    "    else:\n",
    "        num_input_fmaps = tensor.size(1)\n",
    "        num_output_fmaps = tensor.size(0)\n",
    "        receptive_field_size = 1\n",
    "        if tensor.dim() > 2:\n",
    "            receptive_field_size = tensor[0][0].numel()\n",
    "        fan_in = num_input_fmaps * receptive_field_size\n",
    "        fan_out = num_output_fmaps * receptive_field_size\n",
    "\n",
    "    return fan_in, fan_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "       # self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "      #  x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m, xavier=True, param=10.):\n",
    "    classname = m.__class__.__name__\n",
    "    print (classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "       # m.weight.data.normal_(0.0, 0.02)\n",
    "        \n",
    "        if xavier:\n",
    "            z = _calculate_fan_in_and_fan_out(m.weight.data)\n",
    "            std = math.sqrt(2.0 / (z[0] + z[1]))\n",
    "            m.weight.data.uniform_(0.0, std)\n",
    "        else:\n",
    "            m.weight.data.normal_(0.0, 1.0)\n",
    "    if classname.find('Linear') != -1:\n",
    "        if xavier:\n",
    "            z = _calculate_fan_in_and_fan_out(m.weight.data)\n",
    "            std = math.sqrt(2.0 / (z[0] + z[1]))\n",
    "            m.weight.data.uniform_(0.0, std)\n",
    "            \n",
    "            m.bias.data.fill_(0.0)\n",
    "        else:\n",
    "            m.weight.data.normal_(0.0, 1.0)\n",
    "            m.bias.data.normal_\n",
    "            m.weight.data.fill_(-1)\n",
    "            m.bias.data.fill_(-10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d\n",
      "Conv2d\n",
      "Linear\n",
      "Linear\n",
      "Net\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['lr'] = 0.01\n",
    "args['momentum'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['cuda'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args['cuda']:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "    model.eval()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in train_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        train_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        train_loss, correct, len(train_loader.dataset),\n",
    "        100. * correct / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 37.974968\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.302832\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.301864\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.303018\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.302191\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.302680\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.302471\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 2.302501\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.302693\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 2.301928\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.300943\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 2.302522\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 2.303563\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 2.301887\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 2.303252\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 2.303046\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.302683\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 2.300770\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 2.302534\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 2.294522\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.300037\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 2.312358\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 2.280426\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 2.302886\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 2.298898\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 2.285246\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 2.277217\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 2.263732\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 2.258357\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 2.256994\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.254920\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 2.235845\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.259901\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 2.236519\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 2.288698\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 2.246638\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 2.258271\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 2.240249\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 2.233066\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 2.245256\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.215755\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 2.267218\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 2.218983\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 2.231095\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 2.210404\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 2.240909\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 2.194717\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 2.182528\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.225857\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 2.222966\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.202710\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 2.207443\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 2.175417\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 2.179316\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 2.191740\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 2.193346\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 2.202496\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 2.145747\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 2.194869\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 2.176236\n",
      "\n",
      "Test set: Average loss: 2.1648, Accuracy: 10407/60000 (17%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.179313\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 2.178757\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 2.159479\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 2.157227\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 2.139735\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 2.186155\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 2.148238\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 2.156238\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 2.132888\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 2.148420\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 2.117090\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 2.100343\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 2.111511\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 2.139327\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 2.101141\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 2.106129\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 2.132949\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 2.129605\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 2.092124\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 2.117099\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 2.082625\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 2.148860\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 2.087424\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 2.092815\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 2.060716\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 2.090950\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 2.084387\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 2.057801\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 2.081181\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 2.082262\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 2.035293\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 2.075951\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.071129\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 2.067428\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 2.028240\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 2.077982\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 2.040442\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 2.041739\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 1.997437\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 2.065878\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 2.043000\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 2.038471\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 2.018778\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 1.999415\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 1.985157\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 2.029615\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 2.026063\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 1.997645\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.993720\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 1.974929\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 2.017620\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 1.955133\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 1.956471\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 1.956804\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 1.960155\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 1.929118\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 1.973043\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 1.940791\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 1.845348\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 1.909143\n",
      "\n",
      "Test set: Average loss: 1.9072, Accuracy: 21738/60000 (36%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.899145\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 1.885378\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 1.868387\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 1.905947\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 1.946161\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 1.865658\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 1.804655\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 1.805319\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 1.803247\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 1.806308\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 1.819285\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 1.792096\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 1.783245\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 1.694008\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 1.703818\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 1.711399\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.739406\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 1.753199\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 1.614298\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 1.772053\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.627930\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 1.819888\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 1.776877\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 1.632837\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 1.665014\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 1.698976\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 1.659520\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 1.590280\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 1.560736\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 1.458945\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 1.526447\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 1.635986\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.717690\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 1.530387\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 1.498191\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 1.432659\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 1.491707\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 1.437691\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 1.402404\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 1.503478\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.492951\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 1.681444\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 1.380849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 1.682094\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 1.403120\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 1.355701\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 1.470170\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 1.464707\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.464915\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 1.226624\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 1.473872\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 1.443268\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 1.443708\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 1.283865\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 1.375083\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 1.416502\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 1.303685\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 1.330994\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 1.214978\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 1.399117\n",
      "\n",
      "Test set: Average loss: 1.3355, Accuracy: 33697/60000 (56%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.376600\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 1.408404\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 1.295854\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 1.246332\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 1.301767\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 1.220676\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 1.222215\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 1.318673\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 1.371321\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 1.242826\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 1.331363\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 1.182607\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 1.165771\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 1.344644\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 1.300269\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 1.130034\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 1.254912\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 1.186213\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 1.250773\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 1.230888\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 1.143632\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 1.205355\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 1.271967\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 1.153326\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 1.061280\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 1.198338\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 1.194388\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 1.150017\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 1.183862\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 1.084652\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 1.157986\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.982814\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.029824\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 1.043158\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 1.231832\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 1.304793\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 1.172684\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 1.041426\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 1.246034\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 1.103202\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.965707\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 1.077154\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.994900\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 1.367773\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 1.159612\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 1.028786\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.986861\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.943747\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 1.064998\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 1.025374\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.991265\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 1.144809\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.930142\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.909515\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 1.168737\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 1.113258\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 1.038997\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 1.172561\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.929329\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.961490\n",
      "\n",
      "Test set: Average loss: 1.0212, Accuracy: 42242/60000 (70%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.158372\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 1.016033\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.922615\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 1.051368\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.939964\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.838512\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.991048\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 1.135622\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 1.141592\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 1.071784\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.934480\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.972187\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.817620\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.730527\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.896517\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 1.003629\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 1.093571\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 1.097827\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.856287\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.983537\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.945867\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 1.132246\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.866099\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.799870\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 1.061821\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.873940\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.921828\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.765095\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.843267\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.772217\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.844185\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 1.241948\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.760423\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.854137\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.782576\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.783041\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.755761\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.772615\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.802860\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.817623\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.776510\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.904676\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.710254\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.740061\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.754589\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.678422\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.911416\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.807009\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.729237\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.891976\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.704844\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.784061\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.719361\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.797971\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.845371\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.764406\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.835819\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.863492\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.814839\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.782132\n",
      "\n",
      "Test set: Average loss: 0.7224, Accuracy: 47000/60000 (78%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.700349\n",
      "Train Epoch: 6 [1000/60000 (2%)]\tLoss: 0.670851\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 0.664115\n",
      "Train Epoch: 6 [3000/60000 (5%)]\tLoss: 0.704977\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 0.619610\n",
      "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 0.595021\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 0.578998\n",
      "Train Epoch: 6 [7000/60000 (12%)]\tLoss: 0.576647\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.748678\n",
      "Train Epoch: 6 [9000/60000 (15%)]\tLoss: 0.614475\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.589238\n",
      "Train Epoch: 6 [11000/60000 (18%)]\tLoss: 0.744570\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.739389\n",
      "Train Epoch: 6 [13000/60000 (22%)]\tLoss: 0.607183\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 0.767719\n",
      "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 0.601589\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.789838\n",
      "Train Epoch: 6 [17000/60000 (28%)]\tLoss: 0.683728\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 0.632218\n",
      "Train Epoch: 6 [19000/60000 (32%)]\tLoss: 0.581421\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.653214\n",
      "Train Epoch: 6 [21000/60000 (35%)]\tLoss: 0.844648\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 0.504192\n",
      "Train Epoch: 6 [23000/60000 (38%)]\tLoss: 0.518453\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.700081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 0.634906\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 0.587689\n",
      "Train Epoch: 6 [27000/60000 (45%)]\tLoss: 0.595910\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 0.731779\n",
      "Train Epoch: 6 [29000/60000 (48%)]\tLoss: 0.464269\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.556224\n",
      "Train Epoch: 6 [31000/60000 (52%)]\tLoss: 0.601478\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.812522\n",
      "Train Epoch: 6 [33000/60000 (55%)]\tLoss: 0.729513\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 0.570522\n",
      "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 0.723361\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.509404\n",
      "Train Epoch: 6 [37000/60000 (62%)]\tLoss: 0.642995\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 0.650629\n",
      "Train Epoch: 6 [39000/60000 (65%)]\tLoss: 0.726939\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.569543\n",
      "Train Epoch: 6 [41000/60000 (68%)]\tLoss: 0.632711\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 0.515577\n",
      "Train Epoch: 6 [43000/60000 (72%)]\tLoss: 0.568412\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 0.449214\n",
      "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 0.579294\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 0.533204\n",
      "Train Epoch: 6 [47000/60000 (78%)]\tLoss: 0.488587\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.528688\n",
      "Train Epoch: 6 [49000/60000 (82%)]\tLoss: 0.513208\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.593499\n",
      "Train Epoch: 6 [51000/60000 (85%)]\tLoss: 0.501369\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 0.558970\n",
      "Train Epoch: 6 [53000/60000 (88%)]\tLoss: 0.442207\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 0.550059\n",
      "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 0.473002\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.618019\n",
      "Train Epoch: 6 [57000/60000 (95%)]\tLoss: 0.618947\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 0.519504\n",
      "Train Epoch: 6 [59000/60000 (98%)]\tLoss: 0.556242\n",
      "\n",
      "Test set: Average loss: 0.5462, Accuracy: 52588/60000 (88%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.556871\n",
      "Train Epoch: 7 [1000/60000 (2%)]\tLoss: 0.519517\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 0.600875\n",
      "Train Epoch: 7 [3000/60000 (5%)]\tLoss: 0.556168\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 0.643551\n",
      "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 0.531214\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 0.480422\n",
      "Train Epoch: 7 [7000/60000 (12%)]\tLoss: 0.594704\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.479046\n",
      "Train Epoch: 7 [9000/60000 (15%)]\tLoss: 0.628831\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.570498\n",
      "Train Epoch: 7 [11000/60000 (18%)]\tLoss: 0.476282\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.614882\n",
      "Train Epoch: 7 [13000/60000 (22%)]\tLoss: 0.591465\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 0.538956\n",
      "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 0.496616\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.385901\n",
      "Train Epoch: 7 [17000/60000 (28%)]\tLoss: 0.505651\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 0.541010\n",
      "Train Epoch: 7 [19000/60000 (32%)]\tLoss: 0.489132\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.522770\n",
      "Train Epoch: 7 [21000/60000 (35%)]\tLoss: 0.427782\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 0.494065\n",
      "Train Epoch: 7 [23000/60000 (38%)]\tLoss: 0.483667\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.514451\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 0.554354\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 0.409032\n",
      "Train Epoch: 7 [27000/60000 (45%)]\tLoss: 0.632746\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 0.551237\n",
      "Train Epoch: 7 [29000/60000 (48%)]\tLoss: 0.448835\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.348196\n",
      "Train Epoch: 7 [31000/60000 (52%)]\tLoss: 0.328241\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.348099\n",
      "Train Epoch: 7 [33000/60000 (55%)]\tLoss: 0.441611\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 0.477830\n",
      "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 0.528343\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.378621\n",
      "Train Epoch: 7 [37000/60000 (62%)]\tLoss: 0.476110\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 0.304649\n",
      "Train Epoch: 7 [39000/60000 (65%)]\tLoss: 0.502799\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.459248\n",
      "Train Epoch: 7 [41000/60000 (68%)]\tLoss: 0.875345\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 0.418896\n",
      "Train Epoch: 7 [43000/60000 (72%)]\tLoss: 0.364492\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 0.506010\n",
      "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 0.257239\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 0.228065\n",
      "Train Epoch: 7 [47000/60000 (78%)]\tLoss: 0.453530\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.439745\n",
      "Train Epoch: 7 [49000/60000 (82%)]\tLoss: 0.313887\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.602731\n",
      "Train Epoch: 7 [51000/60000 (85%)]\tLoss: 0.647460\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 0.426460\n",
      "Train Epoch: 7 [53000/60000 (88%)]\tLoss: 0.419987\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 0.500963\n",
      "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 0.287826\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.313630\n",
      "Train Epoch: 7 [57000/60000 (95%)]\tLoss: 0.619491\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 0.299106\n",
      "Train Epoch: 7 [59000/60000 (98%)]\tLoss: 0.354130\n",
      "\n",
      "Test set: Average loss: 0.3817, Accuracy: 54621/60000 (91%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.446810\n",
      "Train Epoch: 8 [1000/60000 (2%)]\tLoss: 0.344252\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 0.365245\n",
      "Train Epoch: 8 [3000/60000 (5%)]\tLoss: 0.330379\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 0.372587\n",
      "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 0.425877\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 0.467430\n",
      "Train Epoch: 8 [7000/60000 (12%)]\tLoss: 0.362667\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.442950\n",
      "Train Epoch: 8 [9000/60000 (15%)]\tLoss: 0.275209\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.307337\n",
      "Train Epoch: 8 [11000/60000 (18%)]\tLoss: 0.477179\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.305176\n",
      "Train Epoch: 8 [13000/60000 (22%)]\tLoss: 0.419977\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 0.471971\n",
      "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 0.224482\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.422330\n",
      "Train Epoch: 8 [17000/60000 (28%)]\tLoss: 0.400603\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 0.382802\n",
      "Train Epoch: 8 [19000/60000 (32%)]\tLoss: 0.305997\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.306012\n",
      "Train Epoch: 8 [21000/60000 (35%)]\tLoss: 0.311588\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 0.563139\n",
      "Train Epoch: 8 [23000/60000 (38%)]\tLoss: 0.197761\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.275043\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 0.364507\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 0.348584\n",
      "Train Epoch: 8 [27000/60000 (45%)]\tLoss: 0.362895\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 0.220373\n",
      "Train Epoch: 8 [29000/60000 (48%)]\tLoss: 0.330253\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.326658\n",
      "Train Epoch: 8 [31000/60000 (52%)]\tLoss: 0.280472\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.368612\n",
      "Train Epoch: 8 [33000/60000 (55%)]\tLoss: 0.276336\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 0.380761\n",
      "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 0.403735\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.336335\n",
      "Train Epoch: 8 [37000/60000 (62%)]\tLoss: 0.421485\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 0.213023\n",
      "Train Epoch: 8 [39000/60000 (65%)]\tLoss: 0.322914\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.371095\n",
      "Train Epoch: 8 [41000/60000 (68%)]\tLoss: 0.295143\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 0.339039\n",
      "Train Epoch: 8 [43000/60000 (72%)]\tLoss: 0.213064\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 0.321161\n",
      "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 0.334925\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 0.280655\n",
      "Train Epoch: 8 [47000/60000 (78%)]\tLoss: 0.192728\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.256431\n",
      "Train Epoch: 8 [49000/60000 (82%)]\tLoss: 0.272854\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.275814\n",
      "Train Epoch: 8 [51000/60000 (85%)]\tLoss: 0.317911\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 0.345537\n",
      "Train Epoch: 8 [53000/60000 (88%)]\tLoss: 0.258201\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 0.378197\n",
      "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 0.310680\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.265013\n",
      "Train Epoch: 8 [57000/60000 (95%)]\tLoss: 0.160330\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 0.253571\n",
      "Train Epoch: 8 [59000/60000 (98%)]\tLoss: 0.256141\n",
      "\n",
      "Test set: Average loss: 0.3014, Accuracy: 55761/60000 (93%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.308676\n",
      "Train Epoch: 9 [1000/60000 (2%)]\tLoss: 0.245911\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 0.279301\n",
      "Train Epoch: 9 [3000/60000 (5%)]\tLoss: 0.251300\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 0.266822\n",
      "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 0.278658\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 0.164494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [7000/60000 (12%)]\tLoss: 0.248464\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.246224\n",
      "Train Epoch: 9 [9000/60000 (15%)]\tLoss: 0.359392\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.206863\n",
      "Train Epoch: 9 [11000/60000 (18%)]\tLoss: 0.399275\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.265924\n",
      "Train Epoch: 9 [13000/60000 (22%)]\tLoss: 0.378394\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 0.229378\n",
      "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 0.443525\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.319040\n",
      "Train Epoch: 9 [17000/60000 (28%)]\tLoss: 0.234723\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 0.355311\n",
      "Train Epoch: 9 [19000/60000 (32%)]\tLoss: 0.349724\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.399624\n",
      "Train Epoch: 9 [21000/60000 (35%)]\tLoss: 0.201638\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 0.277345\n",
      "Train Epoch: 9 [23000/60000 (38%)]\tLoss: 0.280970\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.234829\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 0.164563\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 0.308590\n",
      "Train Epoch: 9 [27000/60000 (45%)]\tLoss: 0.208560\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 0.382531\n",
      "Train Epoch: 9 [29000/60000 (48%)]\tLoss: 0.495691\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.203113\n",
      "Train Epoch: 9 [31000/60000 (52%)]\tLoss: 0.267456\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.311939\n",
      "Train Epoch: 9 [33000/60000 (55%)]\tLoss: 0.317993\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 0.270450\n",
      "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 0.242069\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.267773\n",
      "Train Epoch: 9 [37000/60000 (62%)]\tLoss: 0.207331\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 0.237852\n",
      "Train Epoch: 9 [39000/60000 (65%)]\tLoss: 0.201563\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.263495\n",
      "Train Epoch: 9 [41000/60000 (68%)]\tLoss: 0.326574\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 0.286331\n",
      "Train Epoch: 9 [43000/60000 (72%)]\tLoss: 0.247563\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 0.134051\n",
      "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 0.314206\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 0.342292\n",
      "Train Epoch: 9 [47000/60000 (78%)]\tLoss: 0.257319\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.193660\n",
      "Train Epoch: 9 [49000/60000 (82%)]\tLoss: 0.441209\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.212106\n",
      "Train Epoch: 9 [51000/60000 (85%)]\tLoss: 0.206529\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 0.273611\n",
      "Train Epoch: 9 [53000/60000 (88%)]\tLoss: 0.228344\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 0.317916\n",
      "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 0.353561\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.179519\n",
      "Train Epoch: 9 [57000/60000 (95%)]\tLoss: 0.167071\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 0.219862\n",
      "Train Epoch: 9 [59000/60000 (98%)]\tLoss: 0.172450\n",
      "\n",
      "Test set: Average loss: 0.2623, Accuracy: 56183/60000 (94%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.284783\n",
      "Train Epoch: 10 [1000/60000 (2%)]\tLoss: 0.174528\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 0.270002\n",
      "Train Epoch: 10 [3000/60000 (5%)]\tLoss: 0.201714\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 0.189530\n",
      "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 0.321921\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 0.256430\n",
      "Train Epoch: 10 [7000/60000 (12%)]\tLoss: 0.252687\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 0.299451\n",
      "Train Epoch: 10 [9000/60000 (15%)]\tLoss: 0.215572\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.332355\n",
      "Train Epoch: 10 [11000/60000 (18%)]\tLoss: 0.355700\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.309504\n",
      "Train Epoch: 10 [13000/60000 (22%)]\tLoss: 0.336336\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 0.196971\n",
      "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 0.237884\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.287517\n",
      "Train Epoch: 10 [17000/60000 (28%)]\tLoss: 0.216207\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 0.124709\n",
      "Train Epoch: 10 [19000/60000 (32%)]\tLoss: 0.263033\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.147761\n",
      "Train Epoch: 10 [21000/60000 (35%)]\tLoss: 0.307653\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 0.416416\n",
      "Train Epoch: 10 [23000/60000 (38%)]\tLoss: 0.184648\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.252836\n",
      "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 0.279219\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 0.163880\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-b5d98dcc05a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-215-620420c385ce>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fs/home/st684/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fs/home/st684/anaconda2/lib/python2.7/site-packages/torchvision-0.2.0-py2.7.egg/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fs/home/st684/anaconda2/lib/python2.7/site-packages/torchvision-0.2.0-py2.7.egg/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fs/home/st684/anaconda2/lib/python2.7/site-packages/torchvision-0.2.0-py2.7.egg/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \"\"\"\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fs/home/st684/anaconda2/lib/python2.7/site-packages/torchvision-0.2.0-py2.7.egg/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;31m# PIL image mode: 1, L, P, I, F, RGB, YCbCr, RGBA, CMYK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'YCbCr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 50 + 1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-0c60e2432da1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'lr'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
